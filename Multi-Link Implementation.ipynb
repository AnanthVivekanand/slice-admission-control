{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b23f4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "babfa59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestType:\n",
    "    def __init__(self, request_type, bandwidth, service_rate, arrival_rate, source, sink, distribution, switch_rate=None):\n",
    "        # distribution is 1x2 if elastic and 1x1 if static\n",
    "        \n",
    "        self.type = request_type\n",
    "        self.bw = bandwidth\n",
    "        self.service_rate = service_rate\n",
    "        self.arrival_rate = arrival_rate\n",
    "        self.source = source\n",
    "        self.sink = sink\n",
    "        self.distribution = distribution\n",
    "        self.switch_rate = switch_rate\n",
    "\n",
    "class Request:\n",
    "    def __init__(self, request_type, service_time, arrival_time, source, sink, transfer_rate, distribution=None):\n",
    "        self.type = request_type\n",
    "        self.service_time = service_time\n",
    "        self.arrival_time = arrival_time\n",
    "        self.source = source\n",
    "        self.sink = sink\n",
    "        self.bw = transfer_rate\n",
    "        self.request_type = request_type\n",
    "        \n",
    "        if request_type == \"elastic\":\n",
    "            self.distribution = distribution\n",
    "            self.scale_requests = []\n",
    "            \n",
    "    def add_scale_request(self, req): \n",
    "        # we store related scale requests for elastic requests\n",
    "        # not used if static request\n",
    "        self.scale_requests.append(req)\n",
    "            \n",
    "    def get_encoding(self, nodes_in_environment):\n",
    "        # as per our notes, this SHOULD return 1x5 tensor,\n",
    "        # but we have one hot encodings INSIDE this tensor,\n",
    "        # so we will flatten this and return, so the size will be\n",
    "        # larger than 1x5\n",
    "        \n",
    "        # nodes_in_environment is a list of all the nodes in our graph\n",
    "        # eg [\"a\", \"b\", \"c\"]\n",
    "        \n",
    "        # request is [one hot source, one hot destination, bw, service time, one hot type]\n",
    "                \n",
    "        one_hot_source = nn.functional.one_hot(torch.tensor([nodes_in_environment.index(self.source)]), num_classes=len(nodes_in_environment)).flatten()\n",
    "        one_hot_dest   = nn.functional.one_hot(torch.tensor([nodes_in_environment.index(self.sink)]), num_classes=len(nodes_in_environment)).flatten()\n",
    "    \n",
    "        if self.request_type == \"static\" or self.request_type == \"scale\":\n",
    "            one_hot_type = torch.tensor([1, 0])\n",
    "        elif self.request_type == \"elastic\":\n",
    "            one_hot_type = torch.tensor([0, 1])\n",
    "            \n",
    "        encoding = torch.cat([one_hot_source, \n",
    "                             one_hot_dest,\n",
    "                             torch.tensor([self.bw]), \n",
    "                             torch.tensor([self.service_time]),\n",
    "                             one_hot_type])\n",
    "        \n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c5db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Link:\n",
    "    def __init__(self, node_1, node_2, bw_capacity):\n",
    "        self.serving_requests = []\n",
    "        self.nodes = [node_1, node_2]\n",
    "        self.total_bw = bw_capacity\n",
    "        \n",
    "    def reset(self):\n",
    "        self.serving_requests = []\n",
    "        \n",
    "    def add_request(self, request_obj):\n",
    "        self.serving_requests.append(request_obj)\n",
    "        \n",
    "    def remove_request(self, request_obj):\n",
    "        self.serving_requests.remove(request_obj)\n",
    "        \n",
    "    def remaining_bw(self): \n",
    "        # subtracting bw being used from total bw capacity\n",
    "        bw_being_used = 0\n",
    "        for req in self.serving_requests:\n",
    "            bw_being_used += req.bw\n",
    "            \n",
    "        return (self.total_bw - bw_being_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55c30a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    # requests_in_service_encoder = nn.RNN(????, 7)\n",
    "    \n",
    "    def __init__(self, nodes, links, request_blueprints):\n",
    "        \"\"\"\n",
    "        nodes: list of strings where each string is just a name or identifier of a node\n",
    "        links: list of tuples where in tuple t, t[0] is first node, t[1] is another node, and t[2] is bw capacity of the link\n",
    "        request_blueprints: list of DeploymentRequest objects\n",
    "        \"\"\"\n",
    "        self.nodes = nodes\n",
    "        self.links = {}\n",
    "        self.request_history = []\n",
    "        self.E_history = []\n",
    "        self.past_distributions = []\n",
    "        self.request_blueprints = request_blueprints\n",
    "        self.last_time = 0\n",
    "        self.episode_timesteps = 600\n",
    "        \n",
    "        for link in links:\n",
    "            if link[0] not in self.nodes or link[1] not in self.nodes:\n",
    "                raise Exception(\"Node in link \" + str(link) + \" doesn't exist\")\n",
    "            \n",
    "            link_obj = Link(*link)\n",
    "\n",
    "            self.links[link[0] + link[1]] = link_obj\n",
    "            self.links[link[1] + link[0]] = link_obj\n",
    "            \n",
    "        self.request_list = self.create_requests()\n",
    "        self.request_queue = iter(self.request_list)\n",
    "            \n",
    "    def add_request(self, request, path=None): # we want to add this request to a link or path\n",
    "        # path: a list of nodes that the request traverses including source and sink\n",
    "        # if no path is specified, path is assumed to be [req.source, req.sink]\n",
    "        \n",
    "        if path is not None: \n",
    "            nodes = [[path[i], path[i + 1]] for i in range(len(path) - 1)]\n",
    "            for node_pair in nodes:\n",
    "                env.links[node_pair[0] + node_pair[1]].add_request(request)\n",
    "        \n",
    "        else:\n",
    "            self.links[request.source + request.sink].add_request(request)\n",
    "        \n",
    "        self.request_history.append(request)\n",
    "        # print(self.links[request.source + request.sink])\n",
    "    \n",
    "    def reset(self):\n",
    "        for link in self.links.values():\n",
    "            link.reset()\n",
    "        self.request_history = []\n",
    "        self.E_history = []\n",
    "        self.past_distributions = []\n",
    "        self.last_time = 0\n",
    "        self.request_list = env.create_requests()\n",
    "        self.request_queue = iter(self.request_list)\n",
    "        \n",
    "        return env.get_encoding()\n",
    "        \n",
    "    def reward(self, request, decision):\n",
    "        base_rate = 1         # 1 when static\n",
    "        type_bonus = 0.9      # 0.9 when static\n",
    "        if request.type == \"elastic\":\n",
    "            base_rate = request.bw \n",
    "            type_bonus = 1.1                # 1.1 when elastic\n",
    "            \n",
    "        r = request.bw * base_rate * request.service_time * type_bonus\n",
    "        \n",
    "        # if remaining bandwidth on link < 0, very \"bad\" reward\n",
    "        remaining_bw = self.links[request.source + request.sink].remaining_bw()\n",
    "        if remaining_bw < 0:\n",
    "            return (-r * 10)\n",
    "        \n",
    "        if decision == \"accept\":\n",
    "            return r\n",
    "        \n",
    "        if decision == \"reject\":\n",
    "            if request.type == \"static\":\n",
    "                return 0\n",
    "            elif request.type == \"elastic\":\n",
    "                current_sum = torch.tensor([0, 0])\n",
    "                for dist in self.past_distributions:\n",
    "                    current_sum += dist\n",
    "                average_past_distribution = current_sum / len(self.past_distributions)\n",
    "                current_req_distribution = torch.tensor(request.distribution)\n",
    "\n",
    "                return -1 * r * math.exp(-nn.functional.kl_div(average_past_distribution, current_req_distribution))\n",
    "\n",
    "                \n",
    "                \"\"\"\n",
    "                past_distributions = []\n",
    "                for req in self.request_history:\n",
    "                    if req.request_type == \"elastic\":\n",
    "                        past_distributions.append(req.distribution)\n",
    "                \n",
    "                average_past_distribution = torch.mean(past_distributions, dim=1)\n",
    "                current_req_distribution = torch.tensor(request.distribution)\n",
    "                \n",
    "                if bool(average_past_distribution[0] < current_req_distribution[0]):\n",
    "                    return -1 * r * math.exp(-nn.functional.kl_div(average_past_distribution, current_req_distribution))\n",
    "                else:\n",
    "                    return 0\n",
    "                \"\"\"\n",
    "                \n",
    "    def next_req(self):\n",
    "        return next(self.request_queue)\n",
    "                \n",
    "    def step(self, req, action):\n",
    "        # what happens if we have two requests that come in on the same timestep but there is only enough bandwidth for one?\n",
    "        # do we the decision on the second request with knowledge of the first request\n",
    "        # essentially, after we accept the first request, will we submit an updated encoding of the network to the policy network?\n",
    " \n",
    "        # actions is a Nx2 matrix where the first column in the request and second is the decision\n",
    "        # decision is either \"accept\" or \"reject\"\n",
    "        # this is given by our agent\n",
    "                \n",
    "        if action[0] > 0.5:\n",
    "            # accept request\n",
    "            paths = (env.search(req.source, req.sink, [], []))\n",
    "            paths.sort(key=lambda x: len(x)) # sort by shortest path\n",
    "            # select the path we are using\n",
    "            path = paths[action[1:4].argmax()]\n",
    "            \n",
    "            self.add_request(req, path)\n",
    "        \n",
    "            reward = env.reward(req, \"accept\")\n",
    "        elif action[0] < 0.5:\n",
    "            # reject\n",
    "            reward = env.reward(req, \"reject\")\n",
    "        \n",
    "        obs = env.get_encoding()\n",
    "        \n",
    "        done = req.arrival_time > 600\n",
    "        info = None\n",
    "        \n",
    "        return obs, reward, done, info\n",
    "        \n",
    "    def update_requests(self, current_time):\n",
    "        # here, we remove expired requests and update E_history based off of the request stats\n",
    "        \n",
    "        for request in self.request_history:\n",
    "            if (request.arrival_time + request.service_time) > self.last_time and (request.arrival_time + request.service_time) < current_time:\n",
    "                # request has expired, let's remove it from the links\n",
    "                for link in self.links.values():\n",
    "                    if request in link.serving_requests:\n",
    "                        link.remove_request(request)\n",
    "                        \n",
    "                if request.type == \"elastic\":\n",
    "                    time_on_higher_bw = 0\n",
    "                    for scale_req in request.scale_requests:\n",
    "                        time_on_higher_bw += scale_req.service_time\n",
    "\n",
    "                    time_on_lower_bw = request.service_time - time_on_higher_bw\n",
    "\n",
    "                    # calculate E[history]\n",
    "                    request_time = np.array([time_on_lower_bw, time_on_higher_bw])\n",
    "                    request_bw = request.bw\n",
    "                    result = (request_time / request_time.sum()).dot(request_bw)\n",
    "                    self.past_distributions.append(request_time / request_time.sum())\n",
    "                    self.E_history.append(result)\n",
    "\n",
    "    def get_encoding(self):\n",
    "        links_processed = [] \n",
    "        # these will store links that we have already encoded so we don't encode them again\n",
    "        \n",
    "        current_encoding = []\n",
    "        \n",
    "        # h = torch.zeros(7) # assuming 7 for h0 size\n",
    "        # last_out = None\n",
    "        \n",
    "        env_encoding = []\n",
    "        \n",
    "        next_req = self.next_req()\n",
    "        while next_req.type == \"scale\":\n",
    "            next_req = self.next_req()\n",
    "            \n",
    "        self.update_requests(next_req.arrival_time)\n",
    "        \n",
    "        for link in self.links.values():\n",
    "            if link in links_processed:\n",
    "                continue\n",
    "\n",
    "                        \n",
    "            # Commented because we don't want to encode any queue for phase 1\n",
    "            \n",
    "            # for req in link.serving_requests\n",
    "                # request is [one hot source, one hot destination, bw, service time, one hot type]\n",
    "                \n",
    "                # one_hot_source = nn.functional.one_hot(torch.tensor([self.nodes.index(req.source)]), num_classes=len(self.nodes))\n",
    "                # one_hot_dest   = nn.functional.one_hot(torch.tensor([self.nodes.index(req.sink)]), num_classes=len(self.nodes))\n",
    "\n",
    "                # req_tensor = torch.Tensor([]) # mismatched dimensions??!\n",
    "                # last_out, h = self.requests_in_service_encoder(req_tensor, h)\n",
    "\n",
    "            # current_encoding.append(torch.cat(torch.Tensor([link.remaining_bw]), last_out))\n",
    "            # torch.stack(current_encoding)\n",
    "            \n",
    "            # check implementation later\n",
    "            \n",
    "            env_encoding.append(link.remaining_bw())\n",
    "            \n",
    "            links_processed.append(link)\n",
    "            \n",
    "        return torch.tensor(env_encoding), torch.tensor(next_req.get_encoding(env.nodes)), next_req\n",
    "    \n",
    "    def create_requests(self):\n",
    "        requests = []\n",
    "        \n",
    "        for request_type in self.request_blueprints:\n",
    "            arrival_times = []\n",
    "            service_times = []\n",
    "            last_arrival = 0\n",
    "        \n",
    "            while last_arrival < self.episode_timesteps: # we want to generate requests till we reach episode end\n",
    "                last_arrival += np.random.exponential(request_type.arrival_rate)\n",
    "                arrival_times.append(last_arrival)\n",
    "                                \n",
    "            for _ in arrival_times:\n",
    "                service_times.append(np.random.exponential(request_type.service_rate))\n",
    "                \n",
    "            for arrival_time, service_time in zip(arrival_times, service_times):\n",
    "                # start creating requests\n",
    "                \n",
    "                new_request = Request(request_type.type, service_time, arrival_time, request_type.source, request_type.sink, request_type.bw[0], request_type.distribution)\n",
    "                requests.append(new_request)\n",
    "                \n",
    "                if request_type.type == \"elastic\": \n",
    "                    # we will start with the first bandwidth element as starting bw\n",
    "                    # WE ASSUME that bw[0] < bw[1]\n",
    "                    timesteps_from_deployment = 0\n",
    "                    current_bw = request_type.bw[0]\n",
    "                    while timesteps_from_deployment < service_time:\n",
    "                        if current_bw == request_type.bw[0]:\n",
    "                            # we want to generate a scale request to increase bw\n",
    "                            scale_bw = request_type.bw[1] - current_bw\n",
    "                            scale_service_time = np.random.exponential(request_type.switch_rate[0])\n",
    "                            scale_request = Request(\"scale\", scale_service_time, \\\n",
    "                                                    last_arrival + timesteps_from_deployment, request_type.source, \\\n",
    "                                                   request_type.sink, scale_bw)\n",
    "                            requests.append(scale_request)\n",
    "                            new_request.add_scale_request(scale_request)\n",
    "                            \n",
    "                            timesteps_from_deployment += scale_service_time\n",
    "                            current_bw = request_type.bw[0] + scale_bw # also equal to request_type.distribution[1]\n",
    "                        elif current_bw == request_type.bw[1]:\n",
    "                            # we want to go to lower bw and spend some time there\n",
    "                            time_spent_on_lower_bw = np.random.exponential(request_type.switch_rate[1])\n",
    "                            timesteps_from_deployment += time_spent_on_lower_bw\n",
    "                            current_bw = request_type.bw[0]\n",
    "                            \n",
    "        # sort requests by arrival time\n",
    "        requests.sort(key=lambda x: x.arrival_time)\n",
    "        return requests\n",
    "    \n",
    "    def search(self, source, dest, visited_a, paths):\n",
    "        visited_a.append(source)\n",
    "        # print(visited_a)\n",
    "\n",
    "        for link in set(env.links.values()):\n",
    "            visited = visited_a.copy()\n",
    "            if source in link.nodes:\n",
    "                if dest in link.nodes:\n",
    "                    visited.append(dest)\n",
    "                    paths.append(visited)\n",
    "\n",
    "                x = link.nodes.copy()\n",
    "                x.remove(source)\n",
    "                if x[0] not in visited:\n",
    "                    self.search(x[0], dest, visited.copy(), paths)\n",
    "        return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba89a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"], [[\"a\", \"b\", 10], [\"a\", \"c\", 10], [\"b\", \"d\", 10], \\\n",
    "                                                   [\"c\", \"d\", 20], [\"c\", \"e\", 10], [\"d\", \"f\", 10], \\\n",
    "                                                   [\"e\", \"f\", 10]], \\\n",
    "                  [RequestType(\"static\", [2], 0.5, 0.75, \"a\", \"b\", [1]), \\\n",
    "                  RequestType(\"static\", [8], 1, 1.5, \"a\", \"b\", [1]), \\\n",
    "                  RequestType(\"elastic\", [4, 9], 1, 1.5, \"a\", \"b\", [0.8, 0.2], switch_rate=[0.08, 0.02]), \\\n",
    "                  RequestType(\"static\", [1], 1, 1.5, \"c\", \"d\", [1]), \\\n",
    "                  RequestType(\"static\", [7], 0.5, 0.75, \"c\", \"d\", [1]), \\\n",
    "                  RequestType(\"elastic\", [3, 13], 2, 3, \"c\", \"d\", [0.9, 0.1], switch_rate=[0.09, 0.01]), \\\n",
    "                  RequestType(\"static\", [3], 0.5, 0.75, \"e\", \"f\", [1]), \\\n",
    "                   RequestType(\"static\", [6], 1, 1.5, \"e\", \"f\", [1]), \\\n",
    "                    RequestType(\"elastic\", [5, 8], 2, 3, \"e\", \"f\", [0.7, 0.3], switch_rate=[0.07, 0.03])])\n",
    "\n",
    "\n",
    "                # self, request_type, bandwidth, service_rate, arrival_rate, source, sink, distribution, switch_rate=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689388fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(env_encoding, next_req_encoding, next_req_obj):    \n",
    "    # find all paths between source and sink\n",
    "    paths = (env.search(next_req_obj.source, next_req_obj.sink, [], []))\n",
    "    paths.sort(key=lambda x: len(x)) # sort by shortest path\n",
    "    selection = 0\n",
    "    for path in paths:\n",
    "        # check if this path works\n",
    "        works = True\n",
    "        nodes = [[path[i], path[i + 1]] for i in range(len(path) - 1)]\n",
    "        for node_pair in nodes:\n",
    "            if env.links[node_pair[0] + node_pair[1]].remaining_bw() < next_req_obj.bw:\n",
    "                works = False\n",
    "                \n",
    "        if works:\n",
    "            selection = paths.index(path)\n",
    "            selection_one_hot = nn.functional.one_hot(torch.tensor([selection]), num_classes=3).flatten()\n",
    "            return torch.cat([torch.tensor([1]), selection_one_hot])\n",
    "        \n",
    "    return torch.cat([torch.tensor([0]), torch.tensor([0,0,0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8807b843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-2295fd131b55>:202: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(env_encoding), torch.tensor(next_req.get_encoding(env.nodes)), next_req\n",
      "/usr/local/lib/python3.9/site-packages/torch/nn/functional.py:2610: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 10, 10, 20, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 20, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 20, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 20, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 20, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 13, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 13, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 13, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 20, 10, 10,  0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 19, 10, 10,  0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 20, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 20, 10, 10,  0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 20, 10, 10,  0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 20, 10, 10,  0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  8,  8, 18, 10, 10,  0])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 2, 10, 10, 20, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 20, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 20, 10, 10,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 2,  6,  6, 16, 10, 10,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 2,  6,  6, 10,  4,  4,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 2,  6,  6, 10,  4,  4,  2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([2, 6, 6, 3, 4, 4, 2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  6,  6, 10,  4,  4,  2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 8, 10, 10, 14,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10,  7,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10,  6,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10,  6,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10,  6,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10,  6,  4,  4,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 4, 10, 10,  6,  4,  4,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10,  6,  4,  4,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10,  6,  4,  4,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10,  6,  4,  4,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10,  7,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  7,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10,  7,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  7,  4,  4,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6, 10, 10,  0,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 13, 10, 10,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10, 20, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 20, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 17,  7,  7,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6, 10, 10, 12,  2,  2,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6, 10, 10, 11,  2,  2,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([6, 2, 2, 3, 2, 2, 5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10, 10, 10, 15,  5,  5,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 15,  5,  5,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 14,  5,  5,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 14,  5,  5,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 14,  5,  5,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  7,  5,  5,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  4,  5,  5,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  8,  5,  5,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  5,  2,  2,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6, 10, 10,  8,  5,  5,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 11,  5,  5,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10, 10,  5,  5,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([6, 2, 2, 2, 5, 5, 5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([6, 2, 2, 1, 5, 5, 5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([6, 2, 2, 1, 5, 5, 5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([6, 2, 2, 1, 5, 5, 5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([6, 2, 2, 1, 5, 5, 5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10, 12,  5,  5, 10])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10,  5,  5,  5, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10,  5,  5,  5, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10,  5,  5,  5,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10,  5,  5,  5,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10,  5,  5,  5,  2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 4, 10, 10,  5,  5,  5,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 4, 10, 10,  5,  5,  5,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 0, 10, 10,  5,  5,  5,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 10, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 10, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 10, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 10, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 17, 10, 10,  0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 11,  4,  4,  0])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10, 10, 10, 10,  4,  4,  0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 13,  4,  4,  0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 10,  1,  1,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 2, 10, 10, 10,  1,  1,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10, 10, 10, 10,  1,  1,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10, 10, 10, 10,  1,  1,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 13,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 13,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  6,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  6,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  6,  4,  4,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 8, 10, 10, 13,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 13,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 12,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 12,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  9,  1,  1,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([6, 2, 2, 1, 1, 1, 5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([8, 2, 2, 0, 1, 1, 5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([6, 2, 2, 7, 7, 7, 5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 2, 2, 7, 7, 7, 5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 2, 2, 7, 7, 7, 5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 2, 2, 7, 7, 7, 2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 2, 2, 7, 7, 7, 2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 4,  2,  2, 10, 10, 10,  2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 4, 10, 10, 18, 10, 10,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 4, 10, 10, 13,  5,  5,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6, 10, 10,  7,  5,  5,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  4,  2,  2,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6, 10, 10,  4,  2,  2,  2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10, 10, 10, 20, 10, 10,  7])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10, 10, 10, 19, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 19, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 13,  4,  4,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 8, 10, 10, 13,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 13,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10,  7,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 14,  4,  4, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 14,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 14,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  7,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 14,  4,  4,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 20, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 13, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 13, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 20, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 15,  5,  5, 10])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 2, 10, 10,  8,  5,  5, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10,  8,  5,  5,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10,  8,  5,  5,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10,  1,  5,  5,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 6, 6, 8, 1, 1, 0])\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([2, 6, 6, 8, 1, 1, 3])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([2, 6, 6, 8, 1, 1, 0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 6, 6, 8, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  6,  6,  8,  1,  1,  6])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  6,  6,  8,  1,  1,  6])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  8,  1,  1,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6, 15,  1,  1,  6])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  6,  6, 15,  1,  1,  6])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  6,  6, 15,  1,  1,  6])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6, 15,  1,  1,  6])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  6,  6, 15,  1,  1,  6])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  6,  6, 15,  1,  1,  6])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  6,  6, 15,  1,  1,  6])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  8,  1,  1,  6])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  1,  1,  1,  6])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  1,  1,  1,  3])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  1,  1,  1,  0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 6, 6, 1, 1, 1, 0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([0, 6, 6, 8, 1, 1, 0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  6,  6, 15,  1,  1,  3])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  6,  6, 12,  1,  1,  3])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  6,  6, 12,  1,  1,  3])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([2, 6, 6, 5, 1, 1, 3])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([0, 6, 6, 5, 1, 1, 3])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([0, 6, 6, 5, 1, 1, 3])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 2,  6,  6, 12,  1,  1,  3])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  6,  6, 12,  1,  1,  3])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 6, 6, 9, 1, 1, 3])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 2, 2, 5, 1, 1, 3])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([2, 2, 2, 5, 1, 1, 0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 2, 2, 5, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([2, 2, 2, 5, 1, 1, 6])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 2,  6,  6,  5,  5,  5, 10])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([2, 6, 6, 5, 5, 5, 7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 6, 6, 2, 5, 5, 7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 6, 6, 2, 5, 5, 4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([0, 6, 6, 2, 5, 5, 7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([0, 6, 6, 5, 5, 5, 7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6, 10,  5,  5, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6, 15, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 19, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 19, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 19, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 18, 10, 10,  7])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 15, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 15, 10, 10,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 15, 10, 10,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 16, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 16, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 16, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 11,  5,  5, 10])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 4, 10, 10, 11,  5,  5, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 11,  5,  5, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 11,  5,  5, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 11,  5,  5, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 11,  5,  5, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 11,  5,  5,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 11,  5,  5,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 11,  5,  5,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 16, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 13, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 12, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10,  9,  4,  4,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 8, 10, 10,  6,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10,  5,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10,  8,  4,  4,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 8, 10, 10,  6,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10,  4,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 11, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 11, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 11, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 10, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10,  3, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10,  3, 10, 10,  4])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 0, 10, 10,  3, 10, 10,  4])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 2, 10, 10,  6, 10, 10,  4])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10,  6, 10, 10,  4])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10,  3, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  2, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([4, 4, 4, 4, 4, 4, 4])\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([ 4,  4,  4, 11,  4,  4, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0,  4,  4, 11,  4,  4, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 11, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 11,  4,  4,  4])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6, 10, 10,  4,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 11,  4,  4,  4])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 2, 10, 10, 11,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 11,  4,  4,  4])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 0, 10, 10, 11,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 6, 6, 7, 4, 4, 4])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 2,  6,  6, 13, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  6,  6,  6, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 6, 6, 6, 3, 3, 3])\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([2, 6, 6, 6, 3, 3, 3])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  6,  6,  6, 10, 10, 10])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  6,  6,  6, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  6, 10, 10,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  6, 10, 10,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6, 13, 10, 10, 10])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10,  6,  6,  6, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  6, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  0,  4,  4,  4])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10,  6,  6,  0,  4,  4,  4])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  6,  6,  0,  4,  4, 10])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 8,  6,  6,  0,  4,  4, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  7,  4,  4, 10])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  6,  6, 10,  4,  4, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  3,  4,  4, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  3,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  3,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  3,  4,  4,  4])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  6,  6,  3,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6,  3,  4,  4,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6,  6,  6, 16, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6,  6,  6,  9, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6,  6,  6,  8, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6,  6,  6,  9, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6,  6,  6, 16, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6,  6,  6, 16, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4,  6,  6, 16, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  6,  6, 16, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 20, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 20, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 17, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 10, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 10, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 10, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 17, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 10, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 10, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10,  3, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10,  3, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 10, 10, 10,  2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 4, 10, 10,  7,  7,  7,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6, 10, 10,  7,  7,  7,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10,  8,  1,  1,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6, 10, 10, 11,  4,  4,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10, 11,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 11,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  8,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 14, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4,  2,  2,  6, 10, 10,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 4,  2,  2,  6, 10, 10,  2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 8,  2,  2,  6, 10, 10,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 8,  2,  2,  6, 10, 10,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 8,  2,  2,  6, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([8, 2, 2, 0, 4, 4, 5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10, 10, 10,  8,  4,  4,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10, 10, 10,  1,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  1,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  0,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 11,  4,  4,  5])\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([10, 10, 10, 11,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 14,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 14,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 14,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  6,  6, 10,  4,  4,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 2,  6,  6, 15, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  6,  6, 15, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  6,  6, 15, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0,  6,  6, 15, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 16,  7,  7,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 0, 10, 10, 15,  7,  7,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0,  8,  8, 13,  7,  7,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 2, 10, 10, 12,  4,  4,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10,  2,  2,  4,  4,  4,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([6, 2, 2, 5, 4, 4, 5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([4, 2, 2, 5, 4, 4, 5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([4, 2, 2, 5, 4, 4, 5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([4, 2, 2, 5, 4, 4, 5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([4, 2, 2, 5, 4, 4, 5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 13,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 19, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 13,  4,  4,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 2, 10, 10, 10,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 11,  4,  4,  2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 2, 10, 10,  8,  1,  1,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6, 10, 10,  7,  1,  1,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  3,  4,  4,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  0,  4,  4,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([3, 7, 7, 0, 4, 4, 5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([3, 7, 7, 0, 4, 4, 5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([3, 7, 7, 0, 4, 4, 5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([3, 7, 7, 0, 4, 4, 5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([7, 7, 7, 7, 4, 4, 5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([7, 7, 7, 7, 4, 4, 5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([5, 7, 7, 8, 4, 4, 5])\n",
      "tensor([1, 1, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 7, 8, 4, 4, 2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([5, 7, 7, 8, 4, 4, 2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([7, 7, 7, 8, 4, 4, 2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([3, 7, 7, 8, 4, 4, 2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([3, 7, 7, 8, 4, 4, 2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([3, 7, 7, 5, 1, 1, 5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([3, 7, 7, 4, 1, 1, 5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([3, 7, 7, 4, 1, 1, 5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([1, 7, 7, 4, 1, 1, 5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([7, 7, 7, 4, 1, 1, 5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([7, 7, 7, 4, 1, 1, 2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([7, 7, 7, 3, 1, 1, 2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([7, 7, 7, 3, 1, 1, 2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([7, 7, 7, 3, 1, 1, 2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([3, 7, 7, 3, 1, 1, 2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([3, 7, 7, 3, 1, 1, 2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([3, 7, 7, 4, 1, 1, 2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([3, 7, 7, 1, 1, 1, 2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  4,  1,  1,  2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 2, 10, 10,  4,  1,  1,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 10,  4,  4, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 10,  4,  4, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 11,  4,  4, 10])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 0, 10, 10, 11,  4,  4, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 10,  4,  4, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 11,  4,  4, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 11,  4,  4, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 11,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 11,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 11,  4,  4,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 17, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 17, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  2,  2,  9, 10, 10, 10])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 2,  2,  2,  9, 10, 10, 10])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 2,  2,  2,  9, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0,  2,  2,  9, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8,  0,  0,  7, 10, 10,  7])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 8,  0,  0,  7, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0,  0,  0,  7, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0,  2,  2,  9, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0,  2,  2,  9, 10, 10,  4])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([0, 2, 2, 3, 4, 4, 4])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10,  2,  2,  9, 10, 10,  7])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  2,  2, 12, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  2,  2, 12, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  2,  2, 11, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 12, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 12, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 12, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  9, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  9, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  2, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  2, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  1, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10,  8, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10,  1, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([1, 7, 7, 1, 7, 7, 2])\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([ 8, 10, 10, 15, 10, 10,  2])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 8, 10, 10, 19, 10, 10,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10, 10, 10, 12, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 12, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  5, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  5, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  4, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 11, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 11, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 11, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  5,  4,  4,  4])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10, 10, 10,  4,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 3,  3,  3, 11,  4,  4,  4])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10, 10, 10, 18, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 13,  5,  5,  4])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 8, 10, 10, 13,  5,  5,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 13,  5,  5,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 14,  5,  5, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  7,  5,  5, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  7,  5,  5,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  7,  5,  5,  4])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6, 10, 10,  6,  5,  5,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  8,  5,  5,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  1,  5,  5,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  1,  5,  5,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 13, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 13, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 13, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 20, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10, 20, 10, 10,  7])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 0, 10, 10, 20, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 13, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 12, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 13, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 20, 10, 10,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10, 10, 10, 20, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 19, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 19, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 19, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 13,  4,  4, 10])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 4, 10, 10, 19, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 12, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 12, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 12, 10, 10,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  5, 10, 10,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([4, 4, 4, 5, 4, 4, 1])\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([ 4,  4,  4, 16,  4,  4,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 16, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 16, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 16, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 19, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 19, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 12, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 12, 10, 10,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 12, 10, 10,  1])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10, 10, 10, 12, 10, 10,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 12, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 12, 10, 10,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  9,  7,  7,  1])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10, 10, 10,  9,  7,  7,  1])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10, 10, 10,  2,  7,  7,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  2,  7,  7,  1])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([3, 7, 7, 2, 7, 7, 1])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6, 10, 10, 12, 10, 10,  1])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 6,  2,  2,  4, 10, 10, 10])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6,  2,  2,  4, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6,  2,  2,  3, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8,  2,  2,  3, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  2,  2,  3, 10, 10,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  2,  2,  3, 10, 10,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  2,  2,  0, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  2,  2,  0, 10, 10,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10, 10, 10,  8, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 14, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  7, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  4, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  4, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  5, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 16, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 16, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 10,  4,  4,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 6, 10, 10, 16, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10,  9, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10,  9, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4,  2,  2,  1, 10, 10,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 8,  2,  2,  1, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6,  2,  2, 11, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6,  2,  2, 11, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  2,  2, 11, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8, 10, 10, 19, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 6, 10, 10, 19, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 4, 10, 10, 19, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8,  2,  2, 11, 10, 10,  5])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 8,  2,  2, 11, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8,  2,  2,  4, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8,  2,  2,  4, 10, 10,  5])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 8,  2,  2,  4, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8,  2,  2,  1, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 8,  2,  2,  8, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  2,  2,  7, 10, 10,  5])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  2,  2,  7, 10, 10,  2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  2,  2,  5,  7,  7,  2])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([2, 2, 2, 5, 7, 7, 2])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  2,  2,  4,  7,  7,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([8, 2, 2, 4, 7, 7, 7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([2, 2, 2, 4, 7, 7, 7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 15, 10, 10,  7])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 2, 10, 10, 14, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10, 14, 10, 10,  4])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10,  7, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2, 10, 10,  7, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 0, 10, 10,  7, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 2,  8,  8,  5, 10, 10, 10])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([2, 8, 8, 5, 3, 3, 3])\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([ 2, 10, 10, 15,  3,  3,  3])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10,  2,  2, 10,  3,  3,  3])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10,  2,  2, 10,  3,  3,  0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10,  2,  2, 10,  3,  3,  0])\n",
      "tensor([0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10, 10, 10, 19,  3,  3,  0])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([10, 10, 10, 12,  3,  3,  0])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 16,  7,  7, 10])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 8, 10, 10, 16,  7,  7, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  9,  7,  7, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  2,  7,  7, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10,  5, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([10, 10, 10, 12, 10, 10, 10])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10, 10, 10,  5, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 3,  3,  3,  5, 10, 10, 10])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([10, 10, 10,  5, 10, 10, 10])\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([ 3,  3,  3,  5, 10, 10, 10])\n",
      "tensor([1, 0, 1, 0])\n",
      "tensor([ 3,  3,  3,  5, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 1,  3,  3,  5, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 3,  3,  3, 12, 10, 10, 10])\n",
      "tensor([0, 0, 0, 0])\n",
      "tensor([ 3,  3,  3, 12, 10, 10, 10])\n",
      "tensor([1, 1, 0, 0])\n",
      "tensor([ 3,  3,  3, 13, 10, 10,  7])\n",
      "tensor([1, 1, 0, 0])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1aa8de6b8501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_req_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_req_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_req_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0menv_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_req_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_req_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2295fd131b55>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, req, action)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;31m# reject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reject\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2295fd131b55>\u001b[0m in \u001b[0;36mreward\u001b[0;34m(self, request, decision)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mcurrent_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_distributions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                     \u001b[0mcurrent_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m                 \u001b[0maverage_past_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_sum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpast_distributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0mcurrent_req_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0m__array_priority__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m    \u001b[0;31m# prefer Tensor ops over numpy ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_unary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_encoding, next_req_encoding, next_req_obj = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    decision = policy(env_encoding, next_req_encoding, next_req_obj)\n",
    "    \n",
    "    obs, reward, done, info = env.step(next_req_obj, decision)\n",
    "    env_encoding, next_req_encoding, next_req_obj = obs\n",
    "    \n",
    "    print(env_encoding)\n",
    "    print(decision)\n",
    "    # print(env.request_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a2e50143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ab': <__main__.Link at 0x131ac7eb0>,\n",
       " 'ba': <__main__.Link at 0x131ac7eb0>,\n",
       " 'ac': <__main__.Link at 0x131ac7c10>,\n",
       " 'ca': <__main__.Link at 0x131ac7c10>,\n",
       " 'bd': <__main__.Link at 0x131ac7d00>,\n",
       " 'db': <__main__.Link at 0x131ac7d00>,\n",
       " 'cd': <__main__.Link at 0x131ac7c40>,\n",
       " 'dc': <__main__.Link at 0x131ac7c40>,\n",
       " 'ce': <__main__.Link at 0x131ac72e0>,\n",
       " 'ec': <__main__.Link at 0x131ac72e0>,\n",
       " 'df': <__main__.Link at 0x131ac7250>,\n",
       " 'fd': <__main__.Link at 0x131ac7250>,\n",
       " 'ef': <__main__.Link at 0x131ac7b20>,\n",
       " 'fe': <__main__.Link at 0x131ac7b20>}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "009d736a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ab': <__main__.Link at 0x1315e0fa0>,\n",
       " 'ba': <__main__.Link at 0x1315e0fa0>,\n",
       " 'ac': <__main__.Link at 0x1315e8040>,\n",
       " 'ca': <__main__.Link at 0x1315e8040>,\n",
       " 'bd': <__main__.Link at 0x1315e80a0>,\n",
       " 'db': <__main__.Link at 0x1315e80a0>,\n",
       " 'cd': <__main__.Link at 0x1315e8100>,\n",
       " 'dc': <__main__.Link at 0x1315e8100>,\n",
       " 'ce': <__main__.Link at 0x1315e8160>,\n",
       " 'ec': <__main__.Link at 0x1315e8160>,\n",
       " 'df': <__main__.Link at 0x1315e81c0>,\n",
       " 'fd': <__main__.Link at 0x1315e81c0>,\n",
       " 'ef': <__main__.Link at 0x1315e8fd0>,\n",
       " 'fe': <__main__.Link at 0x1315e8fd0>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.links # notice that there are pairs that point to the same link obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9b16b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 10, 10, 20, 10, 10, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_encoding() # this should return the remaining bandwidth on all links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06f11071",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-143fdeb34d1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ab'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserving_requests\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sample encoding of a request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "env.links['ab'].serving_requests[0].get_encoding(env.nodes) # sample encoding of a request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c831713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-18957.5333,  40325.5333], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "current_sum = torch.tensor([0, 0])\n",
    "for dist in env.past_distributions:\n",
    "    current_sum += dist\n",
    "    \n",
    "print(current_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "992a452f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-18957.533292818243"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "\n",
    "for x in env.past_distributions:\n",
    "    a += x[0]\n",
    "    \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f4cb718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6518222148831949\n",
      "0.6699353421824163\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "\n",
    "for x in env.request_history[404].scale_requests:\n",
    "    a += x.service_time\n",
    "    \n",
    "print(a)\n",
    "print(env.request_history[404].service_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86090cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "elastic\n",
      "elastic\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "elastic\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "elastic\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "elastic\n",
      "elastic\n",
      "elastic\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "elastic\n",
      "static\n",
      "elastic\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "elastic\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "elastic\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n",
      "static\n"
     ]
    }
   ],
   "source": [
    "for x in env.request_history:\n",
    "    if x.type == \"e\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8326106c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
